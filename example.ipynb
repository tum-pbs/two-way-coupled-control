{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uK3JjdVZusRy"
   },
   "source": [
    "# Control of Two-way Coupled Fluid Systems with Differentiable Solvers\n",
    "\n",
    "\n",
    "This notebook shows how to train a neural network in an unsupervised way in order for it to act as a controller in an environment with two way coupling.\n",
    "\n",
    "The source code is provided [here](https://github.com/brenerrr/PhiFlow) in the **two_way_coupling branch**.\n",
    "\n",
    "First of all, we need to prepare the current environment by downloading and installing all necessary packages to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sV0Xy0vOg4eZ",
    "outputId": "29159ff6-015e-47c4-8ca9-4f564733f615"
   },
   "outputs": [],
   "source": [
    "#%cd /content/\n",
    "\n",
    "# warning - needs python 3.7!\n",
    "\n",
    "#!rm -rf ./two-way-coupled-control\n",
    "#!git clone https://github.com/tum-pbs/two-way-coupled-control.git\n",
    "#%cd two-way-coupled-control\n",
    "\n",
    "#!pip install torch torchvision torchaudio\n",
    "#&> /dev/null # Supressing output\n",
    "#!pip install . ./\n",
    "#&> /dev/null  # Supressing output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTTwB1IOyH8y"
   },
   "source": [
    "# Inputs\n",
    "\n",
    "All inputs that control training and simulation are set below. The default values below are the ones used to train a controller for a 2 degrees of freedom environment (disc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_qE5k7Ags1sj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from math import ceil\n",
    "from neural_control.neural_networks.NeuralController import NeuralController\n",
    "from neural_control.misc.misc_funcs import *\n",
    "import argparse\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "# ----------------------------------------------\n",
    "# -------------------- Inputs ------------------\n",
    "# ----------------------------------------------\n",
    "seed = 100\n",
    "# paths assume we're in two-way-coupled-control/\n",
    "export_path = \"./storage/diff_2dof/\"\n",
    "simulation_path = \"./storage/ics/training_2dof/\" # Path to IC simulation\n",
    "n_timesteps = 1000 # Number of timesteps per simulation\n",
    "lr_half_life = 201 # Amount of iterations necessary for learning rate dropping by half\n",
    "n_iterations = 1001 # Number of weights updates\n",
    "n_before_backprop = 16 # Number of timesteps before updating weights\n",
    "translation_only = True # 2 DoF\n",
    "past_window = 2 # Number of past states that are sent to the network\n",
    "hyperparams = { # Loss hyperparameters\n",
    "    \"spatial\": 15,\n",
    "    \"velocity\": 5,\n",
    "    \"force\": 0.1,\n",
    "    \"delta_force\": 5.0,\n",
    "    \"angle\": 0,\n",
    "    \"torque\": 0,\n",
    "    \"ang_velocity\": 0,\n",
    "    \"delta_torque\": 0,\n",
    "    \"proximity\": 0.1\n",
    "}\n",
    "learning_rate = 0.01\n",
    "max_acc = 1\n",
    "# -------------------- Less critical inputs --------------------\n",
    "nn_vars = [\n",
    "    \"obs_vx\",\n",
    "    \"obs_vy\",\n",
    "    \"error_x\",\n",
    "    \"error_y\",\n",
    "    \"control_force_x\",\n",
    "    \"control_force_y\"\n",
    "]\n",
    "device_str = \"CPU\"\n",
    "max_ang_acc = 0\n",
    "architecture = \"fc_only\"\n",
    "export_stride = 50\n",
    "model_export_stride = 100\n",
    "optimizer_str = \"AdamW\"\n",
    "destinations_margins = np.array([20,20])\n",
    "destinations_zone_growrate = 0.33\n",
    "# Simulation parameters\n",
    "re = 1000\n",
    "obs_density = 0.15\n",
    "reference_velocity = 1\n",
    "reference_length = 5\n",
    "inflow_on = False\n",
    "dt = 0.1\n",
    "obs_type = \"disc\"\n",
    "obs_width = 5\n",
    "obs_height = 5\n",
    "time_step_scheme = \"RK2\"\n",
    "domain_size = np.array([80,80])\n",
    "obs_xy = [40,40]\n",
    "sponge_intensity = 0.01\n",
    "sponge_size = [5,5,5,5]\n",
    "obs_mass = 11.780972450961725\n",
    "obs_inertia = 49.087385212340514\n",
    "export_vars = [\n",
    "    \"pressure\",\"vx\",\"vy\",\"obs_mask\",\"obs_xy\",\"obs_vx\",\"obs_vy\",\n",
    "    \"control_force_x\",\"control_force_y\",\"fluid_force_x\",\"fluid_force_y\",\n",
    "    \"reference_x\",\"reference_y\",\"loss\",\"loss_velocity\",\"loss_spatial\",\"error_x\",\n",
    "    \"error_y\",\"loss_ang\",\"loss_ang_vel\",\"fluid_torque\",\"vorticity\",\"cfl\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PEjWQ9T7brD"
   },
   "source": [
    "# Pre processing\n",
    "\n",
    "With all inputs set, the simulation and training classes can be initialized as well as generating the objectives that will be used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fpp94Oz27cPR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default value for obs_vx\n",
      "Loading default value for obs_vy\n",
      "Loading default value for obs_ang\n",
      "Loading default value for obs_ang_vel\n",
      "Did not found data of second obstacle\n",
      "\n",
      "\n",
      " Model's state_dict:\n",
      "layers.0.weight \t torch.Size([38, 16])\n",
      "layers.0.bias \t torch.Size([38])\n",
      "layers.1.weight \t torch.Size([38, 38])\n",
      "layers.1.bias \t torch.Size([38])\n",
      "layers.2.weight \t torch.Size([2, 38])\n",
      "layers.2.bias \t torch.Size([2])\n",
      "\n",
      " Total amount of trainable parameters: 2206\n"
     ]
    }
   ],
   "source": [
    "TORCH_BACKEND.set_default_device(\"CPU\")\n",
    "device = torch.device(\"cpu\")\n",
    "# ----------------------------------------------\n",
    "# ---------------- Setup simulation ------------\n",
    "# ----------------------------------------------\n",
    "sim = TwoWayCouplingSimulation(device, translation_only)\n",
    "sim.set_initial_conditions(obs_type, obs_width, obs_height, path=simulation_path)\n",
    "# Reference variables used to map physical values to network inputs/outputs\n",
    "ref_vars = dict(\n",
    "    velocity=reference_velocity,\n",
    "    length=reference_length,\n",
    "    force=obs_mass * max_acc,\n",
    "    angle=PI,\n",
    "    torque=obs_inertia * max_ang_acc,\n",
    "    time=obs_width / reference_velocity,\n",
    "    ang_velocity=reference_velocity / obs_width\n",
    ")\n",
    "destinations_zone_size = domain_size - destinations_margins * 2\n",
    "\n",
    "# ----------------------------------------------\n",
    "# ---------------- Setup training --------------\n",
    "# ----------------------------------------------\n",
    "n_features = defaultdict(lambda: 1)\n",
    "n_past_features = np.sum([n_features[var] for var in nn_vars])\n",
    "n_present_features = np.sum([n_features[var] for var in nn_vars if \"control\" not in var])\n",
    "training_dt = dt\n",
    "model = NeuralController(\n",
    "    f\"{architecture}{past_window}\",\n",
    "    2 if translation_only else 3,\n",
    "    n_present_features,\n",
    "    n_past_features,\n",
    "    past_window)\n",
    "torch.manual_seed(seed + 1)\n",
    "model.to(device)\n",
    "print(\"\\n\\n Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n Total amount of trainable parameters: {total_params}\")\n",
    "optimizer_func = getattr(torch.optim, optimizer_str)\n",
    "optimizer = optimizer_func(model.parameters(), lr=learning_rate)\n",
    "decay = np.exp(np.log(0.5) / lr_half_life)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# --------------- Setup objectives -------------\n",
    "# ----------------------------------------------\n",
    "first_case = 0\n",
    "os.makedirs( f\"{export_path}\", exist_ok=True)\n",
    "torch.save(model.state_dict(),f\"{export_path}/initial_model_{first_case}.pt\")\n",
    "# Number of simulations necessary to achieve desired number of iterations\n",
    "n_simulations = n_iterations / (n_timesteps / n_before_backprop)\n",
    "# Add double the necessary  amount just in case some exhibit early termination\n",
    "n_simulations = ceil(n_simulations) * 2\n",
    "# Create objectives\n",
    "torch.manual_seed(seed + 2)\n",
    "xy = torch.rand(2, n_simulations)\n",
    "ang = torch.rand(n_simulations)\n",
    "for case in range(n_simulations):\n",
    "    growrate = np.min((destinations_zone_growrate * (case + 1), 1.))\n",
    "    margins = (domain_size - destinations_zone_size * growrate) / 2\n",
    "    xy[:, case] = xy[:, case] * destinations_zone_size * growrate + margins\n",
    "    ang[case] = ((ang[case] * 2 * PI - PI) * growrate)\n",
    "# Save objectives\n",
    "objective_xy = xy.numpy().T.tolist()\n",
    "objective_ang = ang.numpy().tolist()\n",
    "objective_xy = xy.to(device)\n",
    "objective_ang = ang.to(device)\n",
    "\n",
    "# Save inputs to json file\n",
    "inp = {\n",
    "    \"export_vars\" : export_vars,\n",
    "    \"translation_only\" : translation_only,\n",
    "    \"architecture\" : architecture,\n",
    "    \"past_window\" : 2,\n",
    "    \"export_stride\" : export_stride,\n",
    "    \"max_acc\" : max_acc,\n",
    "    \"max_ang_acc\": max_ang_acc,\n",
    "    \"device\" : \"CPU\",\n",
    "    \"bypass_tanh\" : False,\n",
    "    \"nn_vars\" : nn_vars,\n",
    "    \"training_dt\" : dt,\n",
    "    \"n_present_features\": int(n_present_features),\n",
    "    \"n_past_features\" : int(n_past_features),\n",
    "    \"ref_vars\": ref_vars,\n",
    "    \"unsupervised\" : {\n",
    "        \"simulation_path\": simulation_path,\n",
    "        \"destinations_zone_growrate\": destinations_zone_growrate,\n",
    "        \"n_timesteps\": n_timesteps,\n",
    "        \"lr_half_life\": lr_half_life,\n",
    "        \"n_iterations\": n_iterations,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_before_backprop\": n_before_backprop,\n",
    "        \"model_export_stride\": model_export_stride,\n",
    "        \"optimizer\": optimizer_str,\n",
    "        \"destinations_margins\": destinations_margins.tolist(),\n",
    "        \"hyperparams\": hyperparams,\n",
    "    }\n",
    "}\n",
    "with open(f'{export_path}/inputs.json', 'w') as f:\n",
    "    json.dump(inp, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNhI10Ls8zei"
   },
   "source": [
    "# Training\n",
    "\n",
    "The network is trained by minimizing the following loss function\n",
    "\n",
    "$$L = O + V + E$$\n",
    "\n",
    "$$O = \\frac{\\beta_{xy}}{l}\\sum_{n=0}^{l-1}\\|e_{xy}^n\\|^2 + \\frac{\\beta_{\\alpha}}{l}\\sum_{n=0}^{l-1} \\|e_{\\alpha}^n\\|^2$$\n",
    "\n",
    "$$V = \\frac{\\beta_{\\dot{x}}}{l}\\sum_{n=0}^{l-1}\\frac{\\|\\dot{x}^n\\|^2}{\\beta_{prox}\\|e_{xy}^n\\|^2 + 1} + \\frac{\\beta_{\\dot{\\alpha}}}{l}\\sum_{n=0}^{l-1}\\frac{\\|\\dot{\\alpha}^n\\|^2}{\\beta_{prox}\\|e_{\\alpha}^n\\|^2 + 1}$$\n",
    "\n",
    "$$ E = \\frac{\\beta_F}{l}\\sum_{n=0}^{l-1} \\|F_c^n\\|^2\n",
    "    + \\frac{\\beta_T}{l}\\sum_{n=0}^{l-1} \\|T_c^n\\|^2 +\n",
    "      \\frac{\\beta_{\\Delta F}}{l}\\sum_{n=0}^{l-1} \\|F_c^n-F_c^{n-1}\\|^2\n",
    "    + \\frac{\\beta_{\\Delta T}}{l}\\sum_{n=0}^{l-1} \\|T_c^n-T_c^{n-1}\\|^2 $$\n",
    "\n",
    "where $\\dot{x}$\n",
    "and $\\dot{\\alpha}$\n",
    "represent velocities,\n",
    "$e$ errors,\n",
    "and $F_c$\n",
    "and $T_c$\n",
    "control efforts. $\\beta$ are hyperparameters that weigh the contribution of each term.\n",
    "\n",
    "Intermediate models are saved during training before all iterations are performed as *trained_model_####.pt*, where #### is a model index.\n",
    "\n",
    "\n",
    "<br>\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/brenerrr/PhiFlow/blob/two_way_coupling/schematic.png?raw=true\" height=250/>\n",
    "<img src=\"https://raw.githubusercontent.com/brenerrr/PhiFlow/two_way_coupling/training_box.gif\" width=\"250\" height=\"250\"/>\n",
    "<figcaption align = \"center\"><b>A schematic of the differentiable solver training: Blue arrows represent the forward pass while red ones illustrate the flow of gradients. Importantly, the loss signal is backpropagated through l simulation steps to provide policy P with long-term feedback about the flow environment.</b></figcaption>\n",
    "</p>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTCMRFW3cltr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuerey/anaconda3/envs/piso_torch/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642814471/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/thuerey/two-way-coupled-control/phi/math/_tensors.py:172: UserWarning: Slicing with sequence should only be used for channel dimensions.\n",
      "  warnings.warn(\"Slicing with sequence should only be used for channel dimensions.\")\n",
      "/home/thuerey/two-way-coupled-control/phi/torch/_torch_backend.py:66: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642814471/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  tensor = torch.tensor(x, device=self.get_default_device().ref)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not save variable loss_velocity\n",
      "Could not save variable loss_spatial\n",
      "Could not save variable loss_ang\n",
      "Could not save variable loss_ang_vel\n",
      "Time left: 0h 1 min\n",
      "Time left: 0h 47 min\n",
      "Time left: 0h 51 min\n",
      "Pressure did not converge. Trying again with different initial guess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuerey/two-way-coupled-control/phi/math/backend/_numpy_backend.py:232: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time left: 1h 31 min\n",
      "Pressure did not converge. Trying again with different initial guess\n",
      "Time left: 1h 32 min\n",
      "Time left: 0h 54 min\n",
      "Time left: 0h 57 min\n",
      "Time left: 0h 52 min\n",
      "Time left: 0h 48 min\n",
      "Time left: 0h 54 min\n",
      "Time left: 0h 51 min\n",
      "Time left: 0h 51 min\n",
      "Time left: 0h 55 min\n",
      "Time left: 0h 59 min\n",
      "Pressure did not converge. Trying again with different initial guess\n",
      "Time left: 1h 32 min\n",
      "Time left: 0h 57 min\n",
      "Time left: 1h 0 min\n",
      "Time left: 1h 0 min\n",
      "Pressure did not converge. Trying again with different initial guess\n",
      "Time left: 1h 26 min\n",
      "Time left: 0h 47 min\n",
      "Time left: 0h 42 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 49 min\n",
      "Time left: 0h 42 min\n",
      "Time left: 0h 39 min\n",
      "Time left: 0h 37 min\n",
      "Time left: 0h 37 min\n",
      "Time left: 0h 36 min\n",
      "Time left: 0h 36 min\n",
      "Time left: 0h 35 min\n",
      "Time left: 0h 36 min\n",
      "Time left: 0h 35 min\n",
      "Time left: 0h 35 min\n",
      "Time left: 0h 35 min\n",
      "Saving model 1\n",
      "Time left: 0h 34 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 32 min\n",
      "Time left: 0h 31 min\n",
      "Time left: 0h 32 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 47 min\n",
      "Time left: 0h 44 min\n",
      "Time left: 0h 40 min\n",
      "Time left: 0h 36 min\n",
      "Time left: 0h 34 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 44 min\n",
      "Time left: 0h 35 min\n",
      "Time left: 0h 32 min\n",
      "Time left: 0h 31 min\n",
      "Time left: 0h 31 min\n",
      "Time left: 0h 30 min\n",
      "Time left: 0h 30 min\n",
      "Time left: 0h 31 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 30 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 30 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 41 min\n",
      "Time left: 0h 39 min\n",
      "Time left: 0h 35 min\n",
      "Time left: 0h 33 min\n",
      "Saving model 2\n",
      "Time left: 0h 32 min\n",
      "Time left: 0h 30 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 28 min\n",
      "Pressure did not converge. Trying again with different initial guess\n",
      "Time left: 0h 52 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 26 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 38 min\n",
      "Time left: 0h 34 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 30 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 26 min\n",
      "Saving model 3\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 26 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 31 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 23 min\n",
      "Time left: 0h 23 min\n",
      "Time left: 0h 22 min\n",
      "Time left: 0h 22 min\n",
      "Time left: 0h 23 min\n",
      "Time left: 0h 22 min\n",
      "Time left: 0h 22 min\n",
      "Time left: 0h 22 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 38 min\n",
      "Time left: 0h 34 min\n",
      "Time left: 0h 28 min\n",
      "Time left: 0h 26 min\n",
      "Time left: 0h 26 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 35 min\n",
      "Saving model 4\n",
      "Time left: 0h 32 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 26 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 22 min\n",
      "Time left: 0h 21 min\n",
      "Time left: 0h 21 min\n",
      "Time left: 0h 20 min\n",
      "Time left: 0h 20 min\n",
      "Time left: 0h 20 min\n",
      "Time left: 0h 20 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 33 min\n",
      "Time left: 0h 30 min\n",
      "Time left: 0h 26 min\n",
      "Time left: 0h 23 min\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 25 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 29 min\n",
      "Time left: 0h 26 min\n",
      "Time left: 0h 23 min\n",
      "Time left: 0h 21 min\n",
      "Time left: 0h 19 min\n",
      "Time left: 0h 19 min\n",
      "Time left: 0h 19 min\n",
      "Time left: 0h 19 min\n",
      "Time left: 0h 18 min\n",
      "Time left: 0h 18 min\n",
      "Time left: 0h 18 min\n",
      "Time left: 0h 19 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 29 min\n",
      "Saving model 5\n",
      "Time left: 0h 24 min\n",
      "Time left: 0h 21 min\n",
      "Time left: 0h 19 min\n",
      "Time left: 0h 18 min\n",
      "Time left: 0h 18 min\n",
      "Time left: 0h 17 min\n",
      "Time left: 0h 17 min\n",
      "Time left: 0h 17 min\n",
      "Time left: 0h 17 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 17 min\n",
      "Time left: 0h 17 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 16 min\n",
      "Time left: 0h 0 min\n",
      "Time left: 0h 27 min\n",
      "Time left: 0h 23 min\n",
      "Time left: 0h 20 min\n",
      "Time left: 0h 17 min\n"
     ]
    }
   ],
   "source": [
    "last_time = time()\n",
    "i_bp = 0\n",
    "case = 0\n",
    "while i_bp < n_iterations:\n",
    "    # Setup case with default initial values\n",
    "    sim.setup_world(\n",
    "        re,\n",
    "        domain_size,\n",
    "        dt,\n",
    "        obs_mass,\n",
    "        obs_inertia,\n",
    "        reference_velocity,\n",
    "        sponge_intensity,\n",
    "        sponge_size,\n",
    "        inflow_on)\n",
    "    # Variables initialization\n",
    "    nn_inputs_past = torch.zeros((past_window, 1, n_past_features)).to(device)\n",
    "    loss_inputs = defaultdict(lambda: torch.zeros((n_before_backprop, 1, 1)).to(device))\n",
    "    if translation_only:\n",
    "        control_effort = torch.zeros(2).to(device)\n",
    "    else:\n",
    "        control_effort = torch.zeros(3).to(device)\n",
    "    last_control_force = torch.zeros(2).to(device)\n",
    "    control_force_global = torch.zeros(2).to(device)\n",
    "    control_force = torch.zeros(2).to(device)\n",
    "    control_force2 = torch.zeros(2).to(device)\n",
    "    control_torque = torch.zeros(1).to(device)\n",
    "    last_control_torque = torch.zeros(1).to(device)\n",
    "    loss = torch.zeros(1).to(device)\n",
    "    loss_terms = defaultdict(lambda: 0)\n",
    "    # Run simulation\n",
    "    for i in range(0, n_timesteps + 1):\n",
    "        # Check CFL in the first iterations due to possible numerical instabilities\n",
    "        if case < 10:\n",
    "            if math.max(math.abs(sim.velocity.values)) * sim.dt > 1.5:\n",
    "                print(\"CFL too big. Resetting simulation\")\n",
    "                break\n",
    "        sim.apply_forces(control_force_global * ref_vars['force'], control_torque * ref_vars['torque'])\n",
    "        sim.advect()\n",
    "        # In case body escapes domain\n",
    "        if math.any(sim.obstacle.geometry.center > domain_size) or math.any(sim.obstacle.geometry.center < (0, 0)):\n",
    "            print(\"Obstacle is out of bounds. Resetting simulation\")\n",
    "            break\n",
    "        sim.make_incompressible()\n",
    "        sim.calculate_fluid_forces()\n",
    "        # Control\n",
    "        nn_inputs_present, loss_inputs_present = extract_inputs(nn_vars, sim, objective_xy[:, case], objective_ang[case], ref_vars, translation_only)\n",
    "        if i < past_window: last_backprop = i  # Wait to backprop until past inputs are cached\n",
    "        else:\n",
    "            control_effort = model(nn_inputs_present.view(1, -1), nn_inputs_past.view(1, -1))\n",
    "            control_force = control_effort[0, :2]\n",
    "            loss_inputs_present['d_control_force_x'], loss_inputs_present['d_control_force_y'] = (control_force - last_control_force)\n",
    "            loss_inputs_present['control_force_x'], loss_inputs_present['control_force_y'] = control_force\n",
    "            last_control_force = control_force\n",
    "            if translation_only: control_force_global = control_force\n",
    "            else:\n",
    "                angle_tensor = -(sim.obstacle.geometry.angle - math.PI / 2.0).native()\n",
    "                control_force_global = rotate(control_force, angle_tensor)  # Control force at global reference of frame (used for visualization only)\n",
    "                # Additional inputs for loss\n",
    "                control_torque = control_effort[0, -1:]\n",
    "                d_control_torque = control_torque - last_control_torque\n",
    "                last_control_torque = control_torque\n",
    "                loss_inputs['d_control_torque'] = d_control_torque\n",
    "                loss_inputs['control_torque'] = control_torque\n",
    "            # Save quantities necessary for loss\n",
    "            for key in loss_inputs_present:\n",
    "                loss_inputs[key] = torch.cat((loss_inputs[key][1:, ...], loss_inputs_present[key].view(1, 1, 1)))\n",
    "            # Update weights\n",
    "            if (i - last_backprop == n_before_backprop):\n",
    "                loss, loss_terms = calculate_loss(loss_inputs, hyperparams, translation_only)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                i_bp += 1\n",
    "                # Export model\n",
    "                if i_bp % model_export_stride == 0:\n",
    "                    model_id = int(i_bp / model_export_stride)\n",
    "                    print(f\"Saving model {model_id}\")\n",
    "                    torch.save(model.state_dict(), os.path.abspath(f\"{export_path}/trained_model_{model_id:04d}.pt\"))\n",
    "                if i_bp == n_iterations: break\n",
    "                lr_scheduler.step()  # Decay learning rate after backprop\n",
    "                optimizer.zero_grad()\n",
    "                # Reset graph\n",
    "                control_force = None\n",
    "                loss_inputs = {key: value.detach() for key, value in loss_inputs.items()}\n",
    "                control_effort = control_effort.detach()\n",
    "                control_torque = control_torque.detach()\n",
    "                last_control_force = last_control_force.detach()\n",
    "                last_control_torque = last_control_torque.detach()\n",
    "                nn_inputs_present = nn_inputs_present.detach()\n",
    "                nn_inputs_past = nn_inputs_past.detach()\n",
    "                control_force_global = control_force_global.detach()\n",
    "                sim.detach_variables()\n",
    "                last_backprop = i\n",
    "        nn_inputs_past = update_inputs(nn_inputs_past, nn_inputs_present, control_effort)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # -------------------- Export ------------------\n",
    "        # ----------------------------------------------\n",
    "        if (i % export_stride != 0): continue\n",
    "        sim.loss = loss.detach()\n",
    "        for key, value in loss_terms.items():\n",
    "            setattr(sim, f\"loss_{key}\", value.detach())\n",
    "        sim.reference_x = objective_xy[0, case].detach()\n",
    "        sim.reference_y = objective_xy[1, case].detach()\n",
    "        sim.control_force_x, sim.control_force_y = control_force_global.detach() * ref_vars['force']\n",
    "        sim.error_x = loss_inputs_present['error_x'].detach() * ref_vars['length']\n",
    "        sim.error_y = loss_inputs_present['error_y'].detach() * ref_vars['length']\n",
    "        if not translation_only:\n",
    "            angle = -(sim.obstacle.geometry.angle - math.PI / 2.0).native().detach()\n",
    "            sim.error_x, sim.error_y = rotate(torch.cat((sim.error_x, sim.error_y)), angle)\n",
    "            sim.reference_ang = objective_ang[case].detach()\n",
    "            sim.error_ang = loss_inputs_present['error_ang'].detach() * ref_vars['angle']\n",
    "            sim.control_torque = control_torque.detach() * ref_vars['torque']\n",
    "        sim.export_data(export_path, case, int(i / export_stride), export_vars, (case == 0 and i == 0))\n",
    "        # Calculate how much time is left\n",
    "        current_time = time()\n",
    "        steps_left = (((n_simulations / 2 - 1) - (case + 1)) * n_timesteps + n_timesteps - (i + 1)) / export_stride\n",
    "        time_left = steps_left * (current_time - last_time) / 3600\n",
    "        last_time = current_time\n",
    "        time_left_hours = int(time_left)\n",
    "        time_left_minutes = int((time_left - time_left_hours) * 60)\n",
    "        print(f\"Time left: {time_left_hours:d}h {time_left_minutes:d} min\")\n",
    "        i += 1\n",
    "    case += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OALCw-L_7QCo"
   },
   "source": [
    "# Testing\n",
    "\n",
    "Although the network is trained in a simple environment with a quiescent flow as initial condition, it is able to handle more complex test scenarios. Here we will run a test with a source of lighter fluid on the bottom of the domain that rises due to buoyancy which creates challenging perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yo9UctdCseC0"
   },
   "outputs": [],
   "source": [
    "!python ./neural_control/testing/generate_tests.py\n",
    "!python ./neural_control/testing/test_networks.py ./storage/diff_2dof 10 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5u1YVbDR7-Jp"
   },
   "source": [
    "# Metrics\n",
    "\n",
    "After the test is done, the metrics of the network performance can be calculated and saved to a json file in *storage/diff_2dof/tests/test2_10/metrics.json*. The code below calculates the metrics and plots the error of different cases used in test 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCr9KZsaqCeS"
   },
   "outputs": [],
   "source": [
    "!python ./neural_control/misc/group_frames.py ./storage/diff_2dof\n",
    "!python ./neural_control/misc/calculate_metrics.py ./storage/diff_2dof\n",
    "\n",
    "# Plot spatial error of cases ran in test\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('./storage/diff_2dof/tests/test2_10/metrics.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "error_xy_all = np.array(data['error_xy_all'])\n",
    "for i, error_xy in enumerate(error_xy_all):\n",
    "    ax.plot(error_xy, label=f\"Case {i}\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.ylabel('Spatial Error')\n",
    "plt.xlabel('Snapshot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm1N2ywiyE-5"
   },
   "source": [
    "# Fields\n",
    "\n",
    "It is also possible to plot the fields shown in the paper for specific snapshots. Below it is shown lighter fluid contours on timestep 1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcHGs3IuRPTD"
   },
   "outputs": [],
   "source": [
    "!python neural_control/visualization/plot_fields.py ./storage/ 2 1500 --folders diff_2dof --backend agg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(20,10))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    # Remove ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    img = mpimg.imread(f'./storage/figs/diff_2dof_smoke_test2_case000{i}_01500.png')\n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
